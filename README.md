Vehicle and Pedestrian Detection & Tracking ğŸš—ğŸš¶â€â™€ï¸

## ğŸš€ Live Demo
Try the deployed app here: [Streamlit Demo Link](https://vehicle-pedestrian-tracking-e2njc6uozbjkuhup6jvzxy.streamlit.app)

https://vehicle-pedestrian-tracking-e2njc6uozbjkuhup6jvzxy.streamlit.app/
ğŸ“Œ Project Overview

This project implements a YOLOv8 segmentation model combined with ByteTrack for detecting and tracking vehicles and pedestrians in videos.

The workflow includes:

Collecting and annotating a dataset.

Training a YOLOv8-Seg model on Google Colab with GPU.

Evaluating model performance and saving best weights.

Building a Streamlit-based web application for video uploads, inference, and annotated result downloads.

Deploying the app on Streamlit Cloud for easy access.

ğŸ“‚ Repository Structure
vehicle-pedestrian-tracking/
â”‚â”€â”€ dataset/             # Train, Val, Test images + labels (YOLO format)
â”‚â”€â”€ notebooks/           # Colab notebooks for training and evaluation
â”‚â”€â”€ models/              # Trained YOLO weights (best.pt)
â”‚â”€â”€ results/             # Evaluation outputs, graphs, sample runs
â”‚â”€â”€ outputs/             # Inference results (annotated videos, JSONs) [ignored in git]
â”‚â”€â”€ uploads/             # Uploaded videos for processing [ignored in git]
â”‚â”€â”€ src/                 # Custom helper scripts
â”‚â”€â”€ archive_old_webapp/  # Archived initial app attempts
â”‚â”€â”€ app.py               # Streamlit web application
â”‚â”€â”€ tracker.py           # Video tracking + YOLO + ByteTrack logic
â”‚â”€â”€ requirements.txt     # Python dependencies
â”‚â”€â”€ .gitignore           # Ignored files/folders (outputs, uploads, cache)
â”‚â”€â”€ README.md            # Project documentation

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/ANIRUDH-SHARMA-25/vehicle-pedestrian-tracking.git
cd vehicle-pedestrian-tracking

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Add Trained Model

Place your trained YOLO weights file (best.pt) inside the models/ folder:

models/best.pt

4ï¸âƒ£ Run Locally
streamlit run app.py


Upload a video (mp4/avi/mov).

The app will run YOLOv8-Seg + ByteTrack.

Outputs:

results.json â†’ frame-wise tracked objects.

annotated_video.mp4 â†’ video with bounding boxes + IDs.

Both can be downloaded directly from the interface.

âœ… Current Progress

Dataset collected & annotated (2 classes: vehicles, pedestrians).

YOLOv8n-Seg model trained (100 epochs on Colab GPU).

Best weights saved (models/best.pt).

Streamlit web application built & tested locally.

Successfully deployed on Streamlit Cloud ğŸ‰.

ğŸ”— Live Demo: Streamlit App Link

ğŸ“Š Next Steps

Fine-tune model with larger dataset for higher accuracy.

Optimize inference speed for larger videos.

Extend app for multi-class tracking (e.g., bikes, buses).

Add support for real-time webcam/RTSP streams.

ğŸ“¦ Requirements

The app requires the following main dependencies:

streamlit>=1.10
ultralytics>=8.0.0
opencv-python-headless
numpy
pillow

ğŸ“ Notes

outputs/ and uploads/ folders are git-ignored (local runtime data only).

Archived early webapp attempts are kept in archive_old_webapp/ for reference.

ByteTrack support is modular â€” can be swapped or extended with other trackers.

âœ¨ Authors: Anirudh Sharma & Team
ğŸ“… 2025


